{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056f2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "import time\n",
    "import findspark\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import pyspark.sql\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "%matplotlib inline\n",
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b292ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rejee\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rejee\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rejee\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\rejee\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rejee\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98314c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(r\"C:\\Users\\rejee\\spark-3.3.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b423375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"BDA\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598abbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-6UT81JN.home:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BDA</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15be5762a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4159a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(\".\\kindle_reviews.csv\", format=\"csv\", sep=\",\", header=\"true\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732c139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|_c0|      asin|helpful|overall|          reviewText|          reviewTime|          reviewerID|        reviewerName|             summary|      unixReviewTime|\n",
      "+---+----------+-------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|B000F83SZQ| [0, 0]|      5|I enjoy vintage b...|          05 5, 2014|      A1F6404F1VG29J|          Avidreader|  Nice vintage story|          1399248000|\n",
      "|  1|B000F83SZQ| [2, 2]|      4|This book is a re...|          01 6, 2014|       AN0N05A9LIJEQ|            critters|        Different...|          1388966400|\n",
      "|  2|B000F83SZQ| [2, 2]|      4|This was a fairly...|          04 4, 2014|       A795DMNCJILA6|                 dot|               Oldie|          1396569600|\n",
      "|  3|B000F83SZQ| [1, 1]|      5|I'd never read an...|         02 19, 2014|      A1FV0SX13TWVXQ|\"Elaine H. Turley...|  I really liked it.|          1392768000|\n",
      "|  4|B000F83SZQ| [0, 1]|      4|If you like perio...|         03 19, 2014|      A3SPTOKDG7WBLN|  Father Dowling Fan|      Period Mystery|          1395187200|\n",
      "|  5|B000F83SZQ| [0, 0]|      4|A beautiful in-de...|         05 26, 2014|      A1RK2OCZDSGC6R|    ubavka seirovska|              Review|          1401062400|\n",
      "|  6|B000F83SZQ| [0, 0]|      4|I enjoyed this on...|         06 10, 2014|      A2HSAKHC3IBRE6|            Wolfmist|Nice old fashione...|          1402358400|\n",
      "|  7|B000F83SZQ| [1, 1]|      4|Never heard of Am...|         03 22, 2014|      A3DE6XGZ2EPADS|                 WPY|Enjoyable reading...|          1395446400|\n",
      "|  8|B000FA64PA| [0, 0]|      5|Darth Maul workin...|         10 11, 2013|      A1UG4Q4D3OAH3A|                 dsa|          Darth Maul|          1381449600|\n",
      "|  9|B000FA64PA| [0, 0]|      4|This is a short s...|         02 13, 2011|       AQZH7YTWQPOBE|            Enjolras|Not bad, not exce...|          1297555200|\n",
      "| 10|B000FA64PA| [0, 0]|      5|I think I have th...|         01 27, 2014|      A1ZT7WV0ZUA0OJ|                Mike|      Audio and book|          1390780800|\n",
      "| 11|B000FA64PA| [0, 0]|      4|Title has nothing...|         09 17, 2011|      A2ZFR72PT054YS|          monkeyluis|Darth Maul...the ...|          1316217600|\n",
      "| 12|B000FA64PA| [0, 0]|      3|Well written. Int...|         12 31, 2013|       A2QK1U70OJ74P|         Sharon Deem|Not bad; it is we...|          1388448000|\n",
      "| 13|B000FA64PK| [0, 0]|      3|Troy Denning's no...|         03 15, 2012|      A3SZMGJMV0G16C|\"Andrew Pruette \"...|Han and Leia reun...|          1331769600|\n",
      "| 14|B000FA64PK| [0, 0]|      5|I am not for sure...|         05 12, 2013|      A3H8PE1UFK04JZ|         Caleb Watts|  Possibly Important|          1368316800|\n",
      "| 15|B000FA64PK| [0, 0]|      5|I really enjoyed ...|          01 2, 2014|      A2EN84QHDRZLP2|          Carl craft|        Another read|          1388620800|\n",
      "| 16|B000FA64PK| [0, 0]|      5|Great read enjoye...|         10 29, 2013|      A1UG4Q4D3OAH3A|                 dsa|            Recovery|          1383004800|\n",
      "| 17|B000FA64PK| [4, 4]|      3|Another well writ...|         04 16, 2009|      A38Z3Q6DTDIH9J|\"Jimmy J. Shaw \"\"...|Star Wars: The Ne...|          1239840000|\n",
      "| 18|B000FA64PK| [0, 1]|      5|This one promises...|         01 27, 2014|      A1ZT7WV0ZUA0OJ|                Mike|       my collection|          1390780800|\n",
      "| 19|B000FA64PK| [0, 0]|      4|\"I have a version...|\"\" so I downloade...| it surely failed...|   like in the DVD's| where it's bille...| but probably not...|\n",
      "+---+----------+-------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c80cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('reviewTime','reviewerName','reviewerID','helpful','unixReviewTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95d8a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- overall: integer (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0586407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', asin='B000F83SZQ', overall=5, reviewText=\"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", summary='Nice vintage story'),\n",
       " Row(_c0='1', asin='B000F83SZQ', overall=4, reviewText=\"This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\", summary='Different...'),\n",
       " Row(_c0='2', asin='B000F83SZQ', overall=4, reviewText=\"This was a fairly interesting read.  It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.  I read for fun and relaxation......I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.\", summary='Oldie')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f7317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+--------------------+--------------------+\n",
      "|_c0|      asin|overall|          reviewText|             summary|\n",
      "+---+----------+-------+--------------------+--------------------+\n",
      "|  0|B000F83SZQ|      5|I enjoy vintage b...|  Nice vintage story|\n",
      "|  1|B000F83SZQ|      4|This book is a re...|        Different...|\n",
      "|  2|B000F83SZQ|      4|This was a fairly...|               Oldie|\n",
      "|  3|B000F83SZQ|      5|I'd never read an...|  I really liked it.|\n",
      "|  4|B000F83SZQ|      4|If you like perio...|      Period Mystery|\n",
      "|  5|B000F83SZQ|      4|A beautiful in-de...|              Review|\n",
      "|  6|B000F83SZQ|      4|I enjoyed this on...|Nice old fashione...|\n",
      "|  7|B000F83SZQ|      4|Never heard of Am...|Enjoyable reading...|\n",
      "|  8|B000FA64PA|      5|Darth Maul workin...|          Darth Maul|\n",
      "|  9|B000FA64PA|      4|This is a short s...|Not bad, not exce...|\n",
      "| 10|B000FA64PA|      5|I think I have th...|      Audio and book|\n",
      "| 11|B000FA64PA|      4|Title has nothing...|Darth Maul...the ...|\n",
      "| 12|B000FA64PA|      3|Well written. Int...|Not bad; it is we...|\n",
      "| 13|B000FA64PK|      3|Troy Denning's no...|Han and Leia reun...|\n",
      "| 14|B000FA64PK|      5|I am not for sure...|  Possibly Important|\n",
      "| 15|B000FA64PK|      5|I really enjoyed ...|        Another read|\n",
      "| 16|B000FA64PK|      5|Great read enjoye...|            Recovery|\n",
      "| 17|B000FA64PK|      3|Another well writ...|Star Wars: The Ne...|\n",
      "| 18|B000FA64PK|      5|This one promises...|       my collection|\n",
      "| 19|B000FA64PK|      4|\"I have a version...| where it's bille...|\n",
      "+---+----------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22eb8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             summary|\n",
      "+--------------------+\n",
      "|  Nice vintage story|\n",
      "|        Different...|\n",
      "|               Oldie|\n",
      "|  I really liked it.|\n",
      "|      Period Mystery|\n",
      "|              Review|\n",
      "|Nice old fashione...|\n",
      "|Enjoyable reading...|\n",
      "|          Darth Maul|\n",
      "|Not bad, not exce...|\n",
      "|      Audio and book|\n",
      "|Darth Maul...the ...|\n",
      "|Not bad; it is we...|\n",
      "|Han and Leia reun...|\n",
      "|  Possibly Important|\n",
      "|        Another read|\n",
      "|            Recovery|\n",
      "|Star Wars: The Ne...|\n",
      "|       my collection|\n",
      "| where it's bille...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('summary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d16f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72f6e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02de60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8d5000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|             summary|overall|\n",
      "+--------------------+-------+\n",
      "|  Nice vintage story|      5|\n",
      "|        Different...|      4|\n",
      "|               Oldie|      4|\n",
      "|  I really liked it.|      5|\n",
      "|      Period Mystery|      4|\n",
      "|              Review|      4|\n",
      "|Nice old fashione...|      4|\n",
      "|Enjoyable reading...|      4|\n",
      "|          Darth Maul|      5|\n",
      "|Not bad, not exce...|      4|\n",
      "|      Audio and book|      5|\n",
      "|Darth Maul...the ...|      4|\n",
      "|Not bad; it is we...|      3|\n",
      "|Han and Leia reun...|      3|\n",
      "|  Possibly Important|      5|\n",
      "|        Another read|      5|\n",
      "|            Recovery|      5|\n",
      "|Star Wars: The Ne...|      3|\n",
      "|       my collection|      5|\n",
      "| where it's bille...|      4|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['summary','overall']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759e3a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+------------------+--------------------+--------------------+\n",
      "|summary|             _c0|                asin|           overall|          reviewText|             summary|\n",
      "+-------+----------------+--------------------+------------------+--------------------+--------------------+\n",
      "|  count|          982820|              982815|            982619|              982597|              982385|\n",
      "|   mean|        491309.0|                null| 4.347801131466011|                null|            Infinity|\n",
      "| stddev|283657.816417951|                null|0.9550557821749521|                null|                 NaN|\n",
      "|    min|               0| 30 Prayers Of Peace|                 1| &#10032; Bianca ...|                    |\n",
      "|    max|             wn\"|looking forward t...|                 5|~~~~~~~~~~~~~Doub...|~~~~~~~His forbid...|\n",
      "+-------+----------------+--------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ef9ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.drop('reviewTime','reviewerName','reviewerID','helpful','unixReviewTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae8d6222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+--------------------+--------------------+\n",
      "|_c0|      asin|overall|          reviewText|             summary|\n",
      "+---+----------+-------+--------------------+--------------------+\n",
      "|  0|B000F83SZQ|      5|I enjoy vintage b...|  Nice vintage story|\n",
      "|  1|B000F83SZQ|      4|This book is a re...|        Different...|\n",
      "|  2|B000F83SZQ|      4|This was a fairly...|               Oldie|\n",
      "|  3|B000F83SZQ|      5|I'd never read an...|  I really liked it.|\n",
      "|  4|B000F83SZQ|      4|If you like perio...|      Period Mystery|\n",
      "|  5|B000F83SZQ|      4|A beautiful in-de...|              Review|\n",
      "|  6|B000F83SZQ|      4|I enjoyed this on...|Nice old fashione...|\n",
      "|  7|B000F83SZQ|      4|Never heard of Am...|Enjoyable reading...|\n",
      "|  8|B000FA64PA|      5|Darth Maul workin...|          Darth Maul|\n",
      "|  9|B000FA64PA|      4|This is a short s...|Not bad, not exce...|\n",
      "| 10|B000FA64PA|      5|I think I have th...|      Audio and book|\n",
      "| 11|B000FA64PA|      4|Title has nothing...|Darth Maul...the ...|\n",
      "| 12|B000FA64PA|      3|Well written. Int...|Not bad; it is we...|\n",
      "| 13|B000FA64PK|      3|Troy Denning's no...|Han and Leia reun...|\n",
      "| 14|B000FA64PK|      5|I am not for sure...|  Possibly Important|\n",
      "| 15|B000FA64PK|      5|I really enjoyed ...|        Another read|\n",
      "| 16|B000FA64PK|      5|Great read enjoye...|            Recovery|\n",
      "| 17|B000FA64PK|      3|Another well writ...|Star Wars: The Ne...|\n",
      "| 18|B000FA64PK|      5|This one promises...|       my collection|\n",
      "| 19|B000FA64PK|      4|\"I have a version...| where it's bille...|\n",
      "+---+----------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53536b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumnRenamed('overall','Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ba262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+--------------------+--------------------+\n",
      "|_c0|      asin|Rating|          reviewText|             summary|\n",
      "+---+----------+------+--------------------+--------------------+\n",
      "|  0|B000F83SZQ|     5|I enjoy vintage b...|  Nice vintage story|\n",
      "|  1|B000F83SZQ|     4|This book is a re...|        Different...|\n",
      "|  2|B000F83SZQ|     4|This was a fairly...|               Oldie|\n",
      "|  3|B000F83SZQ|     5|I'd never read an...|  I really liked it.|\n",
      "|  4|B000F83SZQ|     4|If you like perio...|      Period Mystery|\n",
      "|  5|B000F83SZQ|     4|A beautiful in-de...|              Review|\n",
      "|  6|B000F83SZQ|     4|I enjoyed this on...|Nice old fashione...|\n",
      "|  7|B000F83SZQ|     4|Never heard of Am...|Enjoyable reading...|\n",
      "|  8|B000FA64PA|     5|Darth Maul workin...|          Darth Maul|\n",
      "|  9|B000FA64PA|     4|This is a short s...|Not bad, not exce...|\n",
      "| 10|B000FA64PA|     5|I think I have th...|      Audio and book|\n",
      "| 11|B000FA64PA|     4|Title has nothing...|Darth Maul...the ...|\n",
      "| 12|B000FA64PA|     3|Well written. Int...|Not bad; it is we...|\n",
      "| 13|B000FA64PK|     3|Troy Denning's no...|Han and Leia reun...|\n",
      "| 14|B000FA64PK|     5|I am not for sure...|  Possibly Important|\n",
      "| 15|B000FA64PK|     5|I really enjoyed ...|        Another read|\n",
      "| 16|B000FA64PK|     5|Great read enjoye...|            Recovery|\n",
      "| 17|B000FA64PK|     3|Another well writ...|Star Wars: The Ne...|\n",
      "| 18|B000FA64PK|     5|This one promises...|       my collection|\n",
      "| 19|B000FA64PK|     4|\"I have a version...| where it's bille...|\n",
      "+---+----------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13ec03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+--------------------+------------------+\n",
      "|_c0|      asin|Rating|          reviewText|           summary|\n",
      "+---+----------+------+--------------------+------------------+\n",
      "|  0|B000F83SZQ|     5|I enjoy vintage b...|Nice vintage story|\n",
      "|  1|B000F83SZQ|     4|This book is a re...|      Different...|\n",
      "|  2|B000F83SZQ|     4|This was a fairly...|             Oldie|\n",
      "|  3|B000F83SZQ|     5|I'd never read an...|I really liked it.|\n",
      "|  4|B000F83SZQ|     4|If you like perio...|    Period Mystery|\n",
      "+---+----------+------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7301a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupBy(\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "199328ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Rating| count|\n",
      "+------+------+\n",
      "|  null|   201|\n",
      "|     1| 23018|\n",
      "|     3| 96194|\n",
      "|     5|575264|\n",
      "|     4|254013|\n",
      "|     2| 34130|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = grouped_df.count()\n",
    "\n",
    "counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07db50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a8f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9774b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,IDF,CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "715963bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(inputCol='summary',outputCol='review_token')\n",
    "#stop_words=StopWordsRemover(inputCol='review_token',outputCol='review_stop')\n",
    "countvector=CountVectorizer(inputCol='review_token',outputCol='review_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa4d3b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Rating', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f1b536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexer.transform(df).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "716842e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18218d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,countvector,indexer ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9693b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fit = pipeline.fit(df)\n",
    "dataset = Fit.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa093fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f1715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a53f07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[trainingData, testData] = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "245542f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02d21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04ae5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter = 50, regParam = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa40ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,countvector, indexer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9827e548",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Idf_features does not exist. Available: _c0, asin, Rating, reviewText, summary, review_token, review_count, label",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5536/2426809107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Building MOdel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             raise TypeError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    132\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# must be an Estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             raise TypeError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: Idf_features does not exist. Available: _c0, asin, Rating, reviewText, summary, review_token, review_count, label"
     ]
    }
   ],
   "source": [
    "# Building MOdel\n",
    "lr_model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ac9f986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_e568cd5dbb1a"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10a21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdd7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85591a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6dc84abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   _c0|      asin|Rating|          reviewText|             summary|        review_token|        review_count|label|\n",
      "+------+----------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|100003|B005HAWAZG|     5|I love the Myrtle...|    Simply enjoyable| [simply, enjoyable]|(148303,[73,434],...|  0.0|\n",
      "|100004|B005HAWAZG|     4|Myrtle Clover, a ...|A quirky who-done...|[a, quirky, who-d...|(148303,[0,906],[...|  1.0|\n",
      "|100009|B005HAWAZG|     2|This book was ver...|     Confusing story|  [confusing, story]|(148303,[14,788],...|  3.0|\n",
      "|100014|B005HAWAZG|     4|SPOILER ALERT! Th...|Good book but som...|[good, book, but,...|(148303,[5,9,20,9...|  1.0|\n",
      "|100017|B005HAWAZG|     5|I love these book...|           Excellent|         [excellent]| (148303,[49],[1.0])|  0.0|\n",
      "|100018|B005HAWAZG|     5|I just finished r...|     A Good Read!!!!| [a, good, read!!!!]|(148303,[0,5,924]...|  0.0|\n",
      "|100020|B005HAWAZG|     4|I usually like me...|Myrtle Clover is ...|[myrtle, clover, ...|(148303,[0,16,513...|  1.0|\n",
      "|100028|B005HAWAZG|     4|This book was fun...|          I liked it|      [i, liked, it]|(148303,[10,13,11...|  1.0|\n",
      "| 10003|B0030ZRWY4|     5|Wow!  So much goi...|DELVER MAGIC Book...|[delver, magic, b...|(148303,[6,8,9,43...|  0.0|\n",
      "|100030|B005HAWAZG|     5|GREAT read! Enter...|Progressive Dinne...|[progressive, din...|(148303,[1026,220...|  0.0|\n",
      "|100031|B005HAWAZG|     4|She is a clever c...|More time with My...|[more, time, with...|(148303,[22,38,91...|  1.0|\n",
      "|100035|B005HAWAZG|     4|Not the best Myrt...|fuzzy mystery ins...|[fuzzy, mystery, ...|(148303,[0,6,34,1...|  1.0|\n",
      "|100038|B005HAWAZG|     4|I like this book ...|Nice emjoyable read.|[nice, emjoyable,...|(148303,[65,112,7...|  1.0|\n",
      "|100047|B005HAWAZG|     4|I really like the...|Spunky little old...|[spunky, little, ...|(148303,[76,258,6...|  1.0|\n",
      "|100050|B005HAWAZG|     2|Well written stor...|Progressive dinne...|[progressive, din...|(148303,[1026,220...|  3.0|\n",
      "|100051|B005HAWAZG|     5|This is the secon...|     Another winner!|  [another, winner!]|(148303,[31,885],...|  0.0|\n",
      "|100053|B005HAWAZG|     3|Would read the ne...|           Easy read|        [easy, read]|(148303,[7,109],[...|  2.0|\n",
      "|100057|B005HAWAZG|     5|\"Eighty something...| a sparrow and a ...|[, a, sparrow, an...|(148303,[0,2,4,6,...|  0.0|\n",
      "|100059|B005HAWAZG|     5|A small, Southern...|         Fun & Witty|     [fun, &, witty]|(148303,[32,72,10...|  0.0|\n",
      "| 10006|B0030ZRWY4|     4|This 2nd book cro...|The Delver's worl...|[the, delver's, w...|(148303,[1,22,61,...|  1.0|\n",
      "+------+----------+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9e4bbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'asin',\n",
       " 'Rating',\n",
       " 'reviewText',\n",
       " 'summary',\n",
       " 'review_token',\n",
       " 'review_count',\n",
       " 'label']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c37c05e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column 'prediction' does not exist. Did you mean one of the following? [Rating, asin, reviewText, review_count, review_token, _c0, label, summary];\n'Project [summary#25, Rating#571, label#917, 'prediction]\n+- Project [_c0#17, asin#18, Rating#571, reviewText#21, summary#25, review_token#890, review_count#903, UDF(cast(Rating#571 as string)) AS label#917]\n   +- Project [_c0#17, asin#18, Rating#571, reviewText#21, summary#25, review_token#890, UDF(review_token#890) AS review_count#903]\n      +- Project [_c0#17, asin#18, Rating#571, reviewText#21, summary#25, UDF(summary#25) AS review_token#890]\n         +- Sample 0.7, 1.0, false, 622724739664976348\n            +- Sort [_c0#17 ASC NULLS FIRST, asin#18 ASC NULLS FIRST, Rating#571 ASC NULLS FIRST, reviewText#21 ASC NULLS FIRST, summary#25 ASC NULLS FIRST], false\n               +- Filter atleastnnonnulls(5, _c0#17, asin#18, Rating#571, reviewText#21, summary#25)\n                  +- Project [_c0#17, asin#18, overall#20 AS Rating#571, reviewText#21, summary#25]\n                     +- Project [_c0#17, asin#18, overall#20, reviewText#21, summary#25]\n                        +- Relation [_c0#17,asin#18,helpful#19,overall#20,reviewText#21,reviewTime#22,reviewerID#23,reviewerName#24,summary#25,unixReviewTime#26] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5536/3573297956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Rating'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   2021\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Alice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Bob'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2022\u001b[0m         \"\"\"\n\u001b[1;32m-> 2023\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Column 'prediction' does not exist. Did you mean one of the following? [Rating, asin, reviewText, review_count, review_token, _c0, label, summary];\n'Project [summary#25, Rating#571, label#917, 'prediction]\n+- Project [_c0#17, asin#18, Rating#571, reviewText#21, summary#25, review_token#890, review_count#903, UDF(cast(Rating#571 as string)) AS label#917]\n   +- Project [_c0#17, asin#18, Rating#571, reviewText#21, summary#25, review_token#890, UDF(review_token#890) AS review_count#903]\n      +- Project [_c0#17, asin#18, Rating#571, reviewText#21, summary#25, UDF(summary#25) AS review_token#890]\n         +- Sample 0.7, 1.0, false, 622724739664976348\n            +- Sort [_c0#17 ASC NULLS FIRST, asin#18 ASC NULLS FIRST, Rating#571 ASC NULLS FIRST, reviewText#21 ASC NULLS FIRST, summary#25 ASC NULLS FIRST], false\n               +- Filter atleastnnonnulls(5, _c0#17, asin#18, Rating#571, reviewText#21, summary#25)\n                  +- Project [_c0#17, asin#18, overall#20 AS Rating#571, reviewText#21, summary#25]\n                     +- Project [_c0#17, asin#18, overall#20, reviewText#21, summary#25]\n                        +- Relation [_c0#17,asin#18,helpful#19,overall#20,reviewText#21,reviewTime#22,reviewerID#23,reviewerName#24,summary#25,unixReviewTime#26] csv\n"
     ]
    }
   ],
   "source": [
    "predictions.select('summary','Rating','label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e0c4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021ce17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b211dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac121a06",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "prediction does not exist. Available: _c0, asin, Rating, reviewText, summary, review_token, review_count, label",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5536/237542032.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\ml\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: prediction does not exist. Available: _c0, asin, Rating, reviewText, summary, review_token, review_count, label"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831032b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
